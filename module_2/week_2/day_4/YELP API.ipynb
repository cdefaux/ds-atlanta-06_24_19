{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Yelp API - Codealong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Generate an OAuth token for the yelp API\n",
    "* Make requests using OAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Access Tokens\n",
    "\n",
    "As discussed, in order to use many APIs, one needs to use OAuth which requires an access token. As such, our first step will be to generate this login information so that we can start making some requests.  \n",
    "\n",
    "With that, lets go grab an access token from an API site and make some API calls!\n",
    "Point your browser over to this [yelp page](https://www.yelp.com/developers/v3/manage_app) and start creating an app in order to obtain and api access token:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either sign in to an existing Yelp account, or create a new one, if needed.\n",
    "\n",
    "On the page you see above, simply fill out some sample information such as \"Flatiron Edu API Example\" for the app name, or whatever floats your boat. Afterwards, you should be presented with an API key that you can use to make requests!\n",
    "\n",
    "With that, it's time to start making some api calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As a general rule of thumb, don't store passwords in a main file like this!\n",
    "#Instead, you would normally store those passwords under a sub file like passwords.py which you would then import.\n",
    "#Or even better, as an environment variable that could then be imported!\n",
    "#For now, we'll simply hardcode them into our notebook for simplicity.\n",
    "#client_id = 'bVX1Jsfp4dkIOqw5HOVplg' #Your client ID goes here (as a string)\n",
    "#api_key = 'RTzp-q-TgkJW_NFQogubFvZNRDziXyoR38VbtZMWibDI-FlvB25OE7GmafFEqhTL8_Bk2HlcX24-hRWLMP7Nc6WHO_VXMXldpPBjP0LoPv5EFFELMSI2oll8njhbXHYx' #Your api key goes here (as a string)\n",
    "client_id = 'pKbwczCfvaFcFmfCorc4VQ' #Your client ID goes here (as a string)\n",
    "api_key = 'fBWOue09Dsh-Cr-RLFzmXonaCoHWxG3e9JvztzVJVTV0FdN-yT3OfSCiW3Bxe1W1DupbbqmV5eHer4i1cBQIaH-x6qcWUGzhpTVTxCqkhJulEJV-rIvIQtagTp8wXXYx' #Your api key goes here (as a string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example Request with OAuth <a id=\"oauth_request\"></a>\n",
    "https://www.yelp.com/developers/documentation/v3/get_started\n",
    "\n",
    "In the next lesson, we'll further dissect how to read and translate online documentation like the link here. For now, let's simply look at an example request and dissect it into its consituent parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "term = 'Mexican'\n",
    "location = 'Astoria NY'\n",
    "SEARCH_LIMIT = 10\n",
    "\n",
    "url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "headers = {\n",
    "        'Authorization': 'Bearer {}'.format(api_key),\n",
    "    }\n",
    "\n",
    "url_params = {\n",
    "                'term': term.replace(' ', '+'),\n",
    "                'location': location.replace(' ', '+'),\n",
    "                'limit': SEARCH_LIMIT\n",
    "            }\n",
    "response = requests.get(url, headers=headers, params=url_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)\n",
    "print(type(response.text))\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.json()['businesses'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Down the Request\n",
    "\n",
    "As you can see, there are three main parts to our request.  \n",
    "  \n",
    "They are:\n",
    "* The url\n",
    "* The header\n",
    "* The parameters\n",
    "  \n",
    "The url is fairly straightforward and is simply the base url as described in the documentation (again more details in the upcoming lesson).\n",
    "\n",
    "The header is a dictionary of key-value pairs. In this case, we are using a fairly standard header used by many APIs. It has a strict form where 'Authorization' is the key and 'Bearer YourApiKey' is the value.\n",
    "\n",
    "The parameters are the filters which we wish to pass into the query. These will be embedded into the url when the request is made to the api. Similar to the header, they form key-value pairs. Valid key parameters by which to structure your queries, are described in the API documentation which we'll look at further shortly. A final important note however, is the need to replace spaces with \"+\". This is standard to many requests as URLs cannot contain spaces. (Note that the header itself isn't directly embedded into the url itself and as such, the space between 'Bearer' and YourApiKey is valid.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Response\n",
    "\n",
    "As before, our response object has both a status code, as well as the data itself. With that, let's start with a little data exploration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go a bit further and start to preview what's stored in each of the values for these keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in response.json().keys():\n",
    "    print(key)\n",
    "    value = response.json()[key] #Use standard dictionary formatting\n",
    "    print(type(value)) #What type is it?\n",
    "    print('\\n\\n') #Seperate out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data =response.json()\n",
    "yelp_data['businesses'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagination\n",
    "\n",
    "Now that you have an initial response, you can examine the contents of the json container. For example, you might start with ```response.json().keys()```. Here, you'll see a key for `'total'`, which tells you the full number of matching results given your query parameters. Write a loop (or ideally a function) which then makes successive API calls using the offset parameter to retrieve all of the results (or 5000 for a particularly large result set) for the original query. As you do this, be mindful of how you store the data. Your final goal will be to reformat the data concerning the businesses themselves into a pandas DataFrame from the json objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; use a function or loop to retrieve all the results from your original request\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def yelp_call(url_params, api_key):\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "    response = requests.get(url, headers=headers, params=url_params)\n",
    "    \n",
    "    df = pd.DataFrame(response.json()['businesses'])\n",
    "    return df\n",
    "\n",
    "def all_results(url_params, api_key):\n",
    "    num = response.json()['total']\n",
    "    print('{} total matches found.'.format(num))\n",
    "    cur = 0\n",
    "    dfs = []\n",
    "    while cur < num and cur < 1000:\n",
    "        url_params['offset'] = cur\n",
    "        dfs.append(yelp_call(url_params, api_key))\n",
    "        time.sleep(1) #Wait a second\n",
    "        cur += 50\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "term = 'pizza'\n",
    "location = 'Astoria NY'\n",
    "url_params = {  'term': term.replace(' ', '+'),\n",
    "                'location': location.replace(' ', '+'),\n",
    "                'limit' : 50\n",
    "             }\n",
    "df = all_results(url_params, api_key)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Take the restaurants from the previous question and do an intial exploratory analysis. At minimum, this should include looking at the distribution of features such as price, rating and number of reviews as well as the relations between these dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df.price = df.price.fillna(value=0)\n",
    "price_dict = {\"$\": 1, \"$$\":2, \"$$$\": 3, \"$$$$\":4}\n",
    "df.price = df.price.map(price_dict)\n",
    "\n",
    "pd.plotting.scatter_matrix(df[['price', 'rating', 'review_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
